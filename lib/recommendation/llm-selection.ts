/**
 * Recommendation Pipeline V2 - LLM Selection
 * 
 * Uses GPT-4o-mini to select the final 3 restaurants from candidates
 * and generate personal, short explanations for each.
 */

import OpenAI from 'openai';
import {
  RankedRestaurant,
  Recommendation,
  ConversationContext,
  ChatMessage,
} from './types';

// ============================================================================
// SYSTEM PROMPTS
// ============================================================================

const SYSTEM_PROMPT_HE = `××ª×” ××•××—×” ××¡×¢×“×•×ª ×©×¢×•×–×¨ ×œ×× ×©×™× ×œ××¦×•× ××ª ×”××§×•× ×”××•×©×œ×.

×§×™×‘×œ×ª ×©×™×—×” ×¢× ××©×ª××© ×•×¨×©×™××” ×©×œ 15 ××•×¢××“×™×.
×”××©×™××” ×©×œ×š:
1. ×‘×—×¨ 3 ××¡×¢×“×•×ª ×©××ª××™××•×ª ×‘×“×™×•×§ ×œ××” ×©×”××©×ª××© ×¨×•×¦×”
2. ×œ×›×œ ××¡×¢×“×” ×›×ª×•×‘ × ×™××•×§ ××™×©×™ ×•×§×¦×¨

×”× ×™××•×§ ×¦×¨×™×š:
- ×œ×”×™×•×ª ××©×¤×˜ ××—×“ ××• ×©× ×™×™× ×‘×œ×‘×“
- ×œ×”×¨×’×™×© ×›××™×œ×• ××ª×” ×—×‘×¨ ×©××›×™×¨ ××•×ª×•
- ×œ×”×ª×™×™×—×¡ ×œ××” ×©×”××©×ª××© ×‘×™×§×© ×¡×¤×¦×™×¤×™×ª
- ×œ×”×™×•×ª ×§×¦×¨ ×•×§×•×œ×¢, ×‘×œ×™ ×—×¤×™×¨×•×ª

×“×•×’×××•×ª ×œ× ×™××•×§×™× ×˜×•×‘×™×:
- "×‘×•×œ ××” ×©×—×™×¤×©×ª - ××™×˜×œ×§×™ ××•×ª× ×˜×™ ×¢× ×¤×¡×˜×” ×˜×¨×™×™×”"
- "××§×•× ××•×©×œ× ×œ×“×™×™×˜, ×¨×•×× ×˜×™ ×•×©×§×˜ ×‘×“×™×•×§ ×›××• ×©×¨×¦×™×ª"
- "×”×›×™ ×§×¨×•×‘ ××œ×™×š ×•×”××•×›×œ ×©× ××“×”×™×"
- "×™×“×¢×ª×™ ×©×ª××”×‘ ××ª ×–×” - ×”××‘×•×¨×’×¨×™× ××˜×•×¨×¤×™×"

×“×•×’×××•×ª ×œ× ×™××•×§×™× ×’×¨×•×¢×™× (×œ× ×œ×›×ª×•×‘ ×›×›×”!):
- "×”××¡×¢×“×” ×”×–×• ××¦×™×¢×” ××’×•×•×Ÿ ×¨×—×‘ ×©×œ ×× ×•×ª ××™×›×•×ª×™×•×ª ×‘×¡×‘×™×‘×” × ×¢×™××”..."
- "×× ×™ ×××œ×™×¥ ×¢×œ ×”××§×•× ×”×–×” ×‘×’×œ×œ ×”××•×•×™×¨×” ×”×™×™×—×•×“×™×ª ×•×”××•×›×œ ×”××©×•×‘×—..."

×”×—×–×¨ JSON ×‘×¤×•×¨××˜ ×”×‘× ×‘×œ×‘×“:
{
  "selections": [
    { "google_place_id": "...", "reason": "..." },
    { "google_place_id": "...", "reason": "..." },
    { "google_place_id": "...", "reason": "..." }
  ]
}`;

const SYSTEM_PROMPT_EN = `You are a restaurant expert helping people find the perfect place.

You received a conversation with a user and a list of 15 candidates.
Your task:
1. Select 3 restaurants that perfectly match what the user wants
2. Write a short, personal reason for each

The reason should:
- Be one or two sentences only
- Feel like a friend who knows them
- Reference what the user specifically asked for
- Be short and punchy, no fluff

Good reason examples:
- "Exactly what you're looking for - authentic Italian with fresh pasta"
- "Perfect for your date, romantic and quiet just like you wanted"
- "Closest to you and the food there is amazing"
- "Knew you'd love this - insane burgers"

Bad reason examples (don't write like this!):
- "This restaurant offers a wide variety of quality dishes in a pleasant environment..."
- "I recommend this place because of its unique atmosphere and exquisite food..."

Return JSON in this format only:
{
  "selections": [
    { "google_place_id": "...", "reason": "..." },
    { "google_place_id": "...", "reason": "..." },
    { "google_place_id": "...", "reason": "..." }
  ]
}`;

// ============================================================================
// CANDIDATE FORMATTING
// ============================================================================

/**
 * Format a restaurant candidate for the LLM prompt
 */
function formatCandidate(restaurant: RankedRestaurant, index: number): string {
  const parts = [
    `${index + 1}. ${restaurant.name}`,
    `   ID: ${restaurant.google_place_id}`,
    `   Rating: ${restaurant.google_rating || 'N/A'}/5 (${restaurant.google_reviews_count || 0} reviews)`,
    `   Price: ${'$'.repeat(restaurant.price_level || 2)}`,
    `   Categories: ${restaurant.categories?.join(', ') || 'Restaurant'}`,
    `   Distance: ${restaurant.distanceMeters ? `${Math.round(restaurant.distanceMeters)}m` : 'N/A'}`,
    `   Match Score: ${(restaurant.finalScore * 100).toFixed(0)}%`,
  ];
  
  if (restaurant.summary) {
    parts.push(`   Summary: ${restaurant.summary.substring(0, 150)}...`);
  }
  
  return parts.join('\n');
}

/**
 * Format conversation for the LLM prompt
 */
function formatConversation(messages: ChatMessage[], language: 'he' | 'en'): string {
  const roleNames = language === 'he' 
    ? { user: '××©×ª××©', assistant: '×¢×•×–×¨' }
    : { user: 'User', assistant: 'Assistant' };
  
  return messages
    .map(m => `${roleNames[m.role]}: ${m.content}`)
    .join('\n');
}

// ============================================================================
// LLM SELECTION
// ============================================================================

export interface LLMSelectionResult {
  google_place_id: string;
  reason: string;
}

/**
 * Use LLM to select final 3 restaurants and generate personal reasons
 */
export async function selectWithLLM(
  candidates: RankedRestaurant[],
  context: ConversationContext,
  messages: ChatMessage[],
  openaiApiKey: string
): Promise<LLMSelectionResult[]> {
  const openai = new OpenAI({ apiKey: openaiApiKey });
  
  console.log(`ğŸ¤– LLM Selection: Processing ${candidates.length} candidates`);
  
  // Choose system prompt based on language
  const systemPrompt = context.language === 'he' ? SYSTEM_PROMPT_HE : SYSTEM_PROMPT_EN;
  
  // Format conversation
  const conversationText = formatConversation(messages, context.language);
  
  // Format candidates
  const candidatesText = candidates
    .map((c, i) => formatCandidate(c, i))
    .join('\n\n');
  
  // Build user prompt
  const userPrompt = context.language === 'he'
    ? `×”×©×™×—×” ×¢× ×”××©×ª××©:
${conversationText}

×”××•×¢××“×™× (15 ×”××¡×¢×“×•×ª ×”×˜×•×‘×•×ª ×‘×™×•×ª×¨):
${candidatesText}

×‘×—×¨ 3 ××¡×¢×“×•×ª ×•×›×ª×•×‘ × ×™××•×§ ×§×¦×¨ ×•××™×©×™ ×œ×›×œ ××—×ª.`
    : `Conversation with user:
${conversationText}

Candidates (top 15 restaurants):
${candidatesText}

Select 3 restaurants and write a short, personal reason for each.`;

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.7,
      max_tokens: 500,
    });
    
    const response = completion.choices[0]?.message?.content || '{}';
    
    // Parse JSON response
    let jsonStr = response.trim();
    if (jsonStr.startsWith('```')) {
      jsonStr = jsonStr.replace(/```json?\n?/g, '').replace(/```/g, '');
    }
    
    const parsed = JSON.parse(jsonStr);
    const selections: LLMSelectionResult[] = parsed.selections || [];
    
    console.log(`âœ… LLM selected ${selections.length} restaurants`);
    selections.forEach((s, i) => {
      console.log(`   ${i + 1}. ${s.google_place_id}: "${s.reason}"`);
    });
    
    return selections;
  } catch (error) {
    console.error('LLM Selection error:', error);
    
    // Fallback: return top 3 candidates with generic reasons
    const fallbackReasons = context.language === 'he'
      ? ['×”××œ×¦×” ××•×‘×™×œ×” ×‘×”×ª×× ×œ×”×¢×“×¤×•×ª ×©×œ×š', '××§×•× ××¦×•×™×Ÿ ×©××ª××™× ×œ××” ×©×—×™×¤×©×ª', '××•×¤×¦×™×” × ×”×“×¨×ª ×‘××–×•×¨ ×©×œ×š']
      : ['Top recommendation based on your preferences', 'Great place matching what you asked', 'Excellent option in your area'];
    
    return candidates.slice(0, 3).map((c, i) => ({
      google_place_id: c.google_place_id,
      reason: fallbackReasons[i],
    }));
  }
}

// ============================================================================
// BUILD FINAL RECOMMENDATIONS
// ============================================================================

/**
 * Build final recommendation objects from LLM selections
 */
export function buildRecommendations(
  selections: LLMSelectionResult[],
  candidates: RankedRestaurant[]
): Recommendation[] {
  const recommendations: Recommendation[] = [];
  
  for (const selection of selections) {
    const restaurant = candidates.find(
      c => c.google_place_id === selection.google_place_id
    );
    
    if (restaurant) {
      // Calculate match percentage (0-100)
      // Base on finalScore, but ensure minimum of 70% for recommended items
      const matchPercentage = Math.max(
        70,
        Math.min(99, Math.round(restaurant.finalScore * 100))
      );
      
      recommendations.push({
        restaurant,
        reason: selection.reason,
        matchPercentage,
      });
    }
  }
  
  // If we don't have 3 recommendations, fill with top candidates
  while (recommendations.length < 3 && candidates.length > recommendations.length) {
    const nextCandidate = candidates.find(
      c => !recommendations.some(r => r.restaurant.google_place_id === c.google_place_id)
    );
    
    if (nextCandidate) {
      recommendations.push({
        restaurant: nextCandidate,
        reason: '×”××œ×¦×” × ×•×¡×¤×ª ×©××ª××™××” ×œ×”×¢×“×¤×•×ª ×©×œ×š',
        matchPercentage: Math.max(70, Math.round(nextCandidate.finalScore * 100)),
      });
    } else {
      break;
    }
  }
  
  return recommendations;
}
